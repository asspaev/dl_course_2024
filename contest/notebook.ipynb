{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "from torchmetrics import Accuracy, F1Score, MetricCollection, AUROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Знакомство с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и посмотрим общую информациб о них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>...</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>47.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0   0  35.0       175.0        75.0       86.5             1.2   \n",
       "1   1  45.0       155.0        60.0       82.0             1.2   \n",
       "2   2  35.0       175.0        60.0       74.0             1.2   \n",
       "3   3  60.0       160.0        55.0       74.0             1.2   \n",
       "4   4  40.0       160.0        55.0       71.0             0.9   \n",
       "\n",
       "   eyesight(right)  hearing(left)  hearing(right)  systolic  ...   HDL    LDL  \\\n",
       "0              1.2            1.0             1.0     127.0  ...  58.0  108.0   \n",
       "1              1.0            1.0             1.0     129.0  ...  50.0  110.0   \n",
       "2              1.2            1.0             1.0     100.0  ...  58.0  116.0   \n",
       "3              1.5            1.0             1.0     139.0  ...  73.0   95.0   \n",
       "4              1.2            1.0             1.0     100.0  ...  66.0  103.0   \n",
       "\n",
       "   hemoglobin  Urine protein  serum creatinine   AST   ALT   Gtp  \\\n",
       "0        15.6            1.0               0.9  17.0  14.0  21.0   \n",
       "1        14.0            1.0               0.7  22.0  18.0  14.0   \n",
       "2        14.8            1.0               0.9  20.0  15.0  16.0   \n",
       "3        15.1            1.0               0.7  47.0  31.0  15.0   \n",
       "4        13.1            1.0               0.6  24.0  21.0  13.0   \n",
       "\n",
       "   dental caries  smoking  \n",
       "0            0.0      0.0  \n",
       "1            0.0      0.0  \n",
       "2            0.0      1.0  \n",
       "3            0.0      0.0  \n",
       "4            0.0      0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=\"data_input/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   15000 non-null  int64  \n",
      " 1   age                  15000 non-null  float64\n",
      " 2   height(cm)           15000 non-null  float64\n",
      " 3   weight(kg)           15000 non-null  float64\n",
      " 4   waist(cm)            15000 non-null  float64\n",
      " 5   eyesight(left)       15000 non-null  float64\n",
      " 6   eyesight(right)      15000 non-null  float64\n",
      " 7   hearing(left)        15000 non-null  float64\n",
      " 8   hearing(right)       15000 non-null  float64\n",
      " 9   systolic             15000 non-null  float64\n",
      " 10  relaxation           15000 non-null  float64\n",
      " 11  fasting blood sugar  15000 non-null  float64\n",
      " 12  Cholesterol          15000 non-null  float64\n",
      " 13  triglyceride         15000 non-null  float64\n",
      " 14  HDL                  15000 non-null  float64\n",
      " 15  LDL                  15000 non-null  float64\n",
      " 16  hemoglobin           15000 non-null  float64\n",
      " 17  Urine protein        15000 non-null  float64\n",
      " 18  serum creatinine     15000 non-null  float64\n",
      " 19  AST                  15000 non-null  float64\n",
      " 20  ALT                  15000 non-null  float64\n",
      " 21  Gtp                  15000 non-null  float64\n",
      " 22  dental caries        15000 non-null  float64\n",
      " 23  smoking              15000 non-null  float64\n",
      "dtypes: float64(23), int64(1)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>...</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15001</td>\n",
       "      <td>45.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15002</td>\n",
       "      <td>65.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15003</td>\n",
       "      <td>30.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15004</td>\n",
       "      <td>40.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0  15000  25.0       165.0        65.0       85.0             1.2   \n",
       "1  15001  45.0       165.0        60.0       74.0             1.5   \n",
       "2  15002  65.0       155.0        55.0       72.0             0.8   \n",
       "3  15003  30.0       170.0        85.0       88.0             0.7   \n",
       "4  15004  40.0       155.0        50.0       70.0             0.9   \n",
       "\n",
       "   eyesight(right)  hearing(left)  hearing(right)  systolic  ...  \\\n",
       "0              1.2            1.0             1.0     128.0  ...   \n",
       "1              1.0            1.0             1.0     104.0  ...   \n",
       "2              0.6            1.0             1.0     130.0  ...   \n",
       "3              0.9            1.0             1.0     119.0  ...   \n",
       "4              0.8            1.0             1.0     102.0  ...   \n",
       "\n",
       "   triglyceride   HDL    LDL  hemoglobin  Urine protein  serum creatinine  \\\n",
       "0          92.0  41.0  132.0        15.0            1.0               1.1   \n",
       "1         124.0  54.0  129.0        11.3            1.0               0.7   \n",
       "2         103.0  76.0  128.0        14.4            1.0               0.8   \n",
       "3         212.0  44.0  117.0        14.8            1.0               1.1   \n",
       "4          87.0  68.0  130.0        13.3            1.0               0.9   \n",
       "\n",
       "    AST   ALT   Gtp  dental caries  \n",
       "0  34.0  23.0  14.0            0.0  \n",
       "1  20.0  17.0  11.0            0.0  \n",
       "2  38.0  18.0  24.0            1.0  \n",
       "3  26.0  38.0  19.0            0.0  \n",
       "4  18.0  12.0  14.0            0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv(filepath_or_buffer=\"data_input/test.csv\")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   10000 non-null  int64  \n",
      " 1   age                  10000 non-null  float64\n",
      " 2   height(cm)           10000 non-null  float64\n",
      " 3   weight(kg)           10000 non-null  float64\n",
      " 4   waist(cm)            10000 non-null  float64\n",
      " 5   eyesight(left)       10000 non-null  float64\n",
      " 6   eyesight(right)      10000 non-null  float64\n",
      " 7   hearing(left)        10000 non-null  float64\n",
      " 8   hearing(right)       10000 non-null  float64\n",
      " 9   systolic             10000 non-null  float64\n",
      " 10  relaxation           10000 non-null  float64\n",
      " 11  fasting blood sugar  10000 non-null  float64\n",
      " 12  Cholesterol          10000 non-null  float64\n",
      " 13  triglyceride         10000 non-null  float64\n",
      " 14  HDL                  10000 non-null  float64\n",
      " 15  LDL                  10000 non-null  float64\n",
      " 16  hemoglobin           10000 non-null  float64\n",
      " 17  Urine protein        10000 non-null  float64\n",
      " 18  serum creatinine     10000 non-null  float64\n",
      " 19  AST                  10000 non-null  float64\n",
      " 20  ALT                  10000 non-null  float64\n",
      " 21  Gtp                  10000 non-null  float64\n",
      " 22  dental caries        10000 non-null  float64\n",
      "dtypes: float64(22), int64(1)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_pred.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим DataModule для работы Pytroch Ligthing с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.features = dataframe.drop(columns=['id', 'smoking']).values\n",
    "        self.targets = dataframe['smoking'].values.astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, df: pd.DataFrame, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Разделение на train/val/test\n",
    "        train_size = int(0.7 * len(self.df))\n",
    "        val_size = int(0.15 * len(self.df))\n",
    "        test_size = len(self.df) - train_size - val_size\n",
    "\n",
    "        df_train, df_val, df_test = torch.utils.data.random_split(\n",
    "            self.df, [train_size, val_size, test_size]\n",
    "        )\n",
    "\n",
    "        # Преобразуем обратно в DataFrame\n",
    "        self.train_df = self.df.iloc[df_train.indices].reset_index(drop=True)\n",
    "        self.val_df = self.df.iloc[df_val.indices].reset_index(drop=True)\n",
    "        self.test_df = self.df.iloc[df_test.indices].reset_index(drop=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(SmokingDataset(self.train_df), batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(SmokingDataset(self.val_df), batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(SmokingDataset(self.test_df), batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = SmokingDataModule(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Test Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим callback, чтобы при обучении каждую n-эпоху проводился тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEveryNepochs(Callback):\n",
    "    def __init__(self, every_n_epochs):\n",
    "        self.every_n_epochs = every_n_epochs\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        # Если текущая эпоха делится на n, запускаем тест\n",
    "        if trainer.current_epoch % self.every_n_epochs == 0:\n",
    "            print(f\"Running test at epoch {trainer.current_epoch}\")\n",
    "            trainer.test(model=pl_module)\n",
    "\n",
    "test_callback = TestEveryNepochs(every_n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее были создадны 7 моделей. Каждый раз пробовал разную архитектуру. Лучшей моделью оказалась модель V7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingClassifierV1(pl.LightningModule):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmokingClassifierV1, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.metrics = MetricCollection({\n",
    "            'auroc': AUROC(task='binary'),\n",
    "        })\n",
    "\n",
    "        self.val_metrics = self.metrics.clone(prefix='val_')\n",
    "        self.test_metrics = self.metrics.clone(prefix='test_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.val_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_metrics = self.val_metrics.compute()\n",
    "        self.log_dict(val_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.test_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log_dict(test_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = df.shape[1] - 2  # Исключаем 'id' и 'smoking'\n",
    "model = SmokingClassifierV1(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingClassifierV2(pl.LightningModule):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmokingClassifierV2, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Первый слой: Linear -> BatchNorm -> ReLU\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),  # Нормализация для улучшения сходимости\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Dropout для предотвращения переобучения\n",
    "\n",
    "            # Второй слой: Linear -> BatchNorm -> ReLU\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Третий слой: Linear -> BatchNorm -> ReLU\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Четвертый слой: Linear\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Выходной слой для бинарной классификации\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.metrics = MetricCollection({\n",
    "            'auroc': AUROC(task='binary'),\n",
    "        })\n",
    "\n",
    "        self.val_metrics = self.metrics.clone(prefix='val_')\n",
    "        self.test_metrics = self.metrics.clone(prefix='test_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.val_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_metrics = self.val_metrics.compute()\n",
    "        self.log_dict(val_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.test_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log_dict(test_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = df.shape[1] - 2  # Исключаем 'id' и 'smoking'\n",
    "model = SmokingClassifierV2(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingClassifierV3(pl.LightningModule):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmokingClassifierV3, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Первый слой: Linear -> ReLU\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Второй слой: Linear -> ReLU\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Третий слой: Linear -> ReLU\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Четвёртый слой: Linear -> ReLU\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Пятый слой: Linear -> ReLU\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Шестой слой: Linear -> ReLU\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Седьмой слой: Linear -> ReLU\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Восьмой слой: Linear -> ReLU\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Выходной слой: Linear -> Sigmoid\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.metrics = MetricCollection({\n",
    "            'auroc': AUROC(task='binary'),\n",
    "        })\n",
    "\n",
    "        self.val_metrics = self.metrics.clone(prefix='val_')\n",
    "        self.test_metrics = self.metrics.clone(prefix='test_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.val_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_metrics = self.val_metrics.compute()\n",
    "        self.log_dict(val_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.test_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log_dict(test_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = df.shape[1] - 2  # Исключаем 'id' и 'smoking'\n",
    "model = SmokingClassifierV3(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingClassifierV4(pl.LightningModule):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmokingClassifierV4, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),         # Большая входная размерность\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),                # Нормализация для улучшения сходимости\n",
    "            nn.Dropout(0.3)                     # Dropout для предотвращения переобучения\n",
    "        )\n",
    "        \n",
    "        # Сетку для обработки нелинейных зависимостей\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        \n",
    "        # Добавление слоёв внимания (Attention) для выделения важных признаков\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=32, num_heads=4, dropout=0.1)\n",
    "        \n",
    "        # Слой для вывода на одну категорию (курит/не курит)\n",
    "        self.fc_out = nn.Linear(32, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()  # Для бинарной классификации\n",
    "\n",
    "        self.metrics = MetricCollection({\n",
    "            'auroc': AUROC(task='binary'),\n",
    "        })\n",
    "\n",
    "        self.val_metrics = self.metrics.clone(prefix='val_')\n",
    "        self.test_metrics = self.metrics.clone(prefix='test_')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Применяем embedding\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Применяем полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        # Применяем внимание для выделения наиболее важных признаков\n",
    "        x = x.unsqueeze(0)  # Добавляем размерность для применения внимания\n",
    "        x, _ = self.attention(x, x, x)\n",
    "        x = x.squeeze(0)  # Убираем лишнюю размерность\n",
    "        \n",
    "        # Вывод\n",
    "        x = self.fc_out(x)\n",
    "        x = self.sigmoid(x)  # Получаем вероятность принадлежности к классу \"курит\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.val_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_metrics = self.val_metrics.compute()\n",
    "        self.log_dict(val_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.test_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log_dict(test_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = df.shape[1] - 2  # Исключаем 'id' и 'smoking'\n",
    "model = SmokingClassifierV4(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingClassifierV5(pl.LightningModule):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmokingClassifierV5, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Первый слой: Linear -> ReLU\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Второй слой: Linear -> ReLU\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Третий слой: Linear -> ReLU\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Четвёртый слой: Linear -> ReLU\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Седьмой слой: Linear -> ReLU\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Седьмой слой: Linear -> ReLU\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Восьмой слой: Linear -> ReLU\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Выходной слой: Linear -> Sigmoid\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.metrics = MetricCollection({\n",
    "            'auroc': AUROC(task='binary'),\n",
    "        })\n",
    "\n",
    "        self.val_metrics = self.metrics.clone(prefix='val_')\n",
    "        self.test_metrics = self.metrics.clone(prefix='test_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.val_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_metrics = self.val_metrics.compute()\n",
    "        self.log_dict(val_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.test_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log_dict(test_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = df.shape[1] - 2  # Исключаем 'id' и 'smoking'\n",
    "model = SmokingClassifierV5(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingClassifierV6(pl.LightningModule):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmokingClassifierV6, self).__init__()\n",
    "\n",
    "        # Модель с дополнительными слоями\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),  # Нормализация для улучшения сходимости\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Dropout для предотвращения переобучения\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Выходной слой для бинарной классификации\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()  # Для бинарной классификации\n",
    "        )\n",
    "\n",
    "        # Метрики\n",
    "        self.metrics = MetricCollection({\n",
    "            'auroc': AUROC(task='binary'),\n",
    "        })\n",
    "        self.val_metrics = self.metrics.clone(prefix='val_')\n",
    "        self.test_metrics = self.metrics.clone(prefix='test_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики на вероятностях (не бинарных значениях)\n",
    "        self.val_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_metrics = self.val_metrics.compute()\n",
    "        self.log_dict(val_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.test_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log_dict(test_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Добавление weight decay для L2 регуляризации\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = df.shape[1] - 2  # Исключаем 'id' и 'smoking'\n",
    "model = SmokingClassifierV6(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokingClassifierV7(pl.LightningModule):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmokingClassifierV7, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # Первый слой: Linear -> BatchNorm -> LeakyReLU\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),  # Используем LeakyReLU\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            # Остаточная связь (Residual connection)\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "\n",
    "            # Выходной слой\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()  # Для бинарной классификации\n",
    "        )\n",
    "\n",
    "        # Метрики\n",
    "        self.metrics = MetricCollection({\n",
    "            'auroc': AUROC(task='binary'),\n",
    "        })\n",
    "        self.val_metrics = self.metrics.clone(prefix='val_')\n",
    "        self.test_metrics = self.metrics.clone(prefix='test_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики на вероятностях (не бинарных значениях)\n",
    "        self.val_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_metrics = self.val_metrics.compute()\n",
    "        self.log_dict(val_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        \n",
    "        # Обновляем метрики\n",
    "        self.test_metrics.update(y_hat, y.int())\n",
    "\n",
    "        acc = ((y_hat > 0.5).int() == y.int()).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log_dict(test_metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Оптимизатор\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        \n",
    "        # Scheduler для уменьшения learning rate\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "\n",
    "        # Возвращаем оптимизатор и scheduler как список\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',  # Метрика, которую нужно отслеживать\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = df.shape[1] - 2  # Исключаем 'id' и 'smoking'\n",
    "model = SmokingClassifierV7(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель в течении 10 эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type             | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model        | Sequential       | 50.6 K | train\n",
      "1 | metrics      | MetricCollection | 0      | train\n",
      "2 | val_metrics  | MetricCollection | 0      | train\n",
      "3 | test_metrics | MetricCollection | 0      | train\n",
      "----------------------------------------------------------\n",
      "50.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.6 K    Total params\n",
      "0.202     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcb7597bc474d0686389ca397233446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e6dfcc7c4b4d109aa9fe7696506eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9499fc527f479c8c4619a8fc1781d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a24a0bed234c76be86e75f2026343e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4368a861ef2c47e09f0038ec7c0482a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229f1634ee4a4e44bf545a22d8af228d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945e74d17aca46b083b8c4ec41d2ed47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827c839d122b479ebeb1ab48fa0e1bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9121c56e010a48a182a57c7afe79bd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe36a1642e541e4ad73952d07cda75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0621025409434b87abfcd3bc150a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab165c3fe8c4d77a1866d6a4c6690cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d3c92980404ed98b781fe2383ffd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=11` reached.\n",
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2685d961494488a8dc6ae34093a7246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8111110925674438\n",
      "       test_auroc           0.8923875093460083\n",
      "        test_loss           0.39220476150512695\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.39220476150512695,\n",
       "  'test_acc': 0.8111110925674438,\n",
       "  'test_auroc': 0.8923875093460083}]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=11, \n",
    "    callbacks=[TQDMProgressBar(refresh_rate=10), test_callback],\n",
    "    logger=TensorBoardLogger(save_dir='lightning_logs', name='smoking_classifier', version='v7')\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дообучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом пункте я постоянно подгружал чекпоинты для дообучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем путь к чекпоинту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './lightning_logs/smoking_classifier/v7/checkpoints/epoch=100-step=33229.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory lightning_logs\\smoking_classifier\\v7\\checkpoints exists and is not empty.\n",
      "Restoring states from the checkpoint path at ./lightning_logs/smoking_classifier/v7/checkpoints/epoch=100-step=33229.ckpt\n",
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name         | Type             | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model        | Sequential       | 50.6 K | train\n",
      "1 | metrics      | MetricCollection | 0      | train\n",
      "2 | val_metrics  | MetricCollection | 0      | train\n",
      "3 | test_metrics | MetricCollection | 0      | train\n",
      "----------------------------------------------------------\n",
      "50.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.6 K    Total params\n",
      "0.202     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Restored all states from the checkpoint at ./lightning_logs/smoking_classifier/v7/checkpoints/epoch=100-step=33229.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6136e8621ff2453286871058c8c1c9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eb3a0cf4874a4991b7862d0bac7f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1cb9c1b130466891db21ca3258d946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2313c5cb9ca48c2b3bceb2576a9cabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef0c9b2c29b4786ae4e1c7d9871d1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841d5dfefbd74b708bba926d2ac93997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdde5bfc6d3d4b3f9737a5af2364d866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48a3116dee1419ba05f7dfd6efb23e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848e6c42168343d1b437fad3657a5d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f616ddfc7ca84794a5eb8c398e9add55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec4120bb7eb4380a7f6b2857613d842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf5922e30404753b77e148c576f1445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fc0e0d41af4b479ba774f297bb8e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b59b6778bc477f93ca1ed2c6ec8427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec2211a86f540cc83caacfffe7a88da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db805d9bb88435a9f062bbdedbd5286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b016401e1af408a9188965726e5ca18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a1dfa4555d4a1fae9a3414f4b3a909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29f6546832345f897814fa73722e79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5e2937693a4c0ea6e130a602190eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0be735f3c54e5a9237a37697e7ed1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2025ad94197c47f3afffae1be364b81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e3054c60cd4db1a0aa1482e860a87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ef4298327848aabeb245fe6d1a0be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb559ad6df84437bdb7bf0286a314c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95849fc0b40a4b26ae651e34a2fbdae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73e0818265f4d8e81a1dddacefb9a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28637d16f0f24c98b34dc581d55b6625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b0ba35e0a64cc89f88f9bf0541267f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8e8082a63c4e43a2e272216b46e6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541fa75349d344a88a6c1fc35c67a75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7dbcd1876e4c7dbf66c1fe67796d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4014d99e381d47ffb5607106fbd1f190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82167917ca37462caee1c91f00e90947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffee1f219ce4f3bbb0220efe5f49730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a123152a03f647fb89d05049fb269db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b54bf674c46400dabb347ee24a5b8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac03c4ec5db499c89e7d7ac7402ad7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255b9ebe1324494b81912880094e2c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5522ca484b824e5a8e7e5af220cf54d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4b62e470eb4e4b9de9e67b8c38a1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfb549908e0426986f8aa091d65f06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7af0c81082f4d829ee6799530e088d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dcb3b4c8a545c7b5cf153c5e5f61e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0c4b2f4ecf437991826fbd985d1d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e764022f4b4011a6590252699349dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8db38e18684427380c379b484d64926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cbb4f6d0ac475193fe4f75b3be87ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26dd56df38e42a297c13fce444f03c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1dc326f9a0499fab0792ae699d71fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8063f6f73dc84f0e9b5bef5f3397ea99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c579f7df2ae42cb91ff62dc5d359a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c255399c5554bf9811b2fd22593cc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e069ef80314e9196b98a88a77de9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010705bed79a4207a87710400c57b1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110949cc008948e79af34e7936dd7353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99634643507649ab86cec2f58bdeff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f272c2d00c6423f8e2229c4ff4b1ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94d0f3b37ec448a90e7a1d4fc89d548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422b36d0ad7b40649b7c31ef43f2feb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3025642065894e70bb22d53d70398333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a04b77ead240a68a2ef69f8df7893d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f8f438bb6b40e082fa9d18b7e6e9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032a00c637a945539053ece886e270fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf5efab905e4a70b83b9d9cd2ca50c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9befcf1f24434ef4866bb7a39d876aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a338f134ae5d429fb813a27b3996f6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e04ded09e3c4f4f95585bed1cef7509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0b8eed2a5d446f866fe354bdfb0400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc684496bf54c869a62b0bf16b3b388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f51006da310415b9363f1ce15ccc8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e072011c098a44a5b9bb65ec82c9b328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd590341009b4ea29909f562b969c44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11db95ec60c4406927fba38cbcf7d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608348681f644fadbc609827f41c5567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f5740200c54ee39e671054908e0678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448908fe6dde4c8f9496c359b1772543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6373e9e48e3407b9335cb83c3f32072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ece959146b146e9888d17439c2386dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871304dd5def4109b3b30f70b96a7c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffc0470862f4a85bfb2ab647c71c3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76877865a9a44965b8491ce69bd29982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc09f3c48ca48c1aba8b759ec1c7702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7f55361af14a4fa78f33225fd2c024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6c75bf03f94fa895a462bd6b0a5d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82f8be2e8574e25ac6898250184bfea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ad18e8a7bd4d3cb8971a23a0598b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f4ac43c83e485893223bad56620963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9dda41963f41c9abc19652f4979c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf99e92749ec408282fa813aaea94feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23656661205f4cb6bd0e64a8e7f9fe53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967515a4268e4654b80f1bbedfe10532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fc95a6d48a453080d9b10747e99aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3caad5fb9494fbdadac4c6bc5f1a4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba1db779ef246fab159367de829bcdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5c30252ba9442e8cdba82fa71a6d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e19872d84df404da22984e369b61889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e29fde77ad24fba88a3d0f5912e1596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f43d94d6c2244ebadd89c300562a23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690fa6975f52479c9ecb2c394d29f610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87962c827cc34362a9fcfb1f126f1e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58161f24bcb742dc96cda52bf2da50e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=201` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=201,  # Увеличь количество эпох\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=10), test_callback],\n",
    "    logger=TensorBoardLogger(save_dir='lightning_logs', name='smoking_classifier', version='v7')\n",
    ")\n",
    "\n",
    "# Продолжаем обучение с чекпойнта\n",
    "trainer.fit(model, data_module, ckpt_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\ITMO\\Semestr_1\\dl_course_2024\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcd9b4a94d24327b29d5d7d0f24b089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7933333516120911\n",
      "       test_auroc           0.8753673434257507\n",
      "        test_loss           0.4135120213031769\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4135120213031769,\n",
       "  'test_acc': 0.7933333516120911,\n",
       "  'test_auroc': 0.8753673434257507}]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_pred['id']\n",
    "X_pred = df_pred.drop(columns=['id']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим нужную версию модели для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghost\\AppData\\Local\\Temp\\ipykernel_8516\\4227480806.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('./lightning_logs/smoking_classifier/v7/checkpoints/epoch=10-step=3619.ckpt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SmokingClassifierV7(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.1)\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.1)\n",
       "    (11): Dropout(p=0.3, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): LeakyReLU(negative_slope=0.1)\n",
       "    (15): Dropout(p=0.4, inplace=False)\n",
       "    (16): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (17): LeakyReLU(negative_slope=0.1)\n",
       "    (18): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (19): Sigmoid()\n",
       "  )\n",
       "  (metrics): MetricCollection(\n",
       "    (auroc): BinaryAUROC()\n",
       "  )\n",
       "  (val_metrics): MetricCollection(\n",
       "    (auroc): BinaryAUROC(),\n",
       "    prefix=val_\n",
       "  )\n",
       "  (test_metrics): MetricCollection(\n",
       "    (auroc): BinaryAUROC(),\n",
       "    prefix=test_\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SmokingClassifierV7(input_size=X_pred.shape[1])\n",
    "checkpoint = torch.load('./lightning_logs/smoking_classifier/v7/checkpoints/epoch=10-step=3619.ckpt')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_pred, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_tensor).squeeze().numpy()\n",
    "# predictions = (predictions > 0.5).astype(int).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним результаты предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'id': ids, 'smoking': predictions})\n",
    "output_df.to_csv('./data_output/predictions15.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь проводились сравнения версий моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14064), started 2:18:20 ago. (Use '!kill 14064' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-72ff5d2a386ecbe0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-72ff5d2a386ecbe0\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
